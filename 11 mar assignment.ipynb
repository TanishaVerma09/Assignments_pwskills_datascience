{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2cd62ff-f844-4422-b7d1-87aa19dba303",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c35d3d1-7cf7-4a99-9b5f-01b3090e795b",
   "metadata": {},
   "source": [
    "Both t-tests and z-tests are statistical tests used to make inferences about population parameters based on sample data. The main difference between the two lies in the assumptions about the population variance and the sample size.\n",
    "\n",
    "t-test:\n",
    "A t-test is used when the population standard deviation is unknown and needs to be estimated from the sample data. It is suitable for small sample sizes (typically less than 30) and follows a t-distribution. There are two main types of t-tests: the one-sample t-test, which compares the mean of a sample to a known population mean, and the two-sample t-test, which compares the means of two independent samples.\n",
    "\n",
    "z-test:\n",
    "A z-test is used when the population standard deviation is known or when the sample size is large (typically greater than 30). It follows a standard normal distribution (z-distribution). Z-tests are often used for large sample hypothesis testing and confidence interval estimation.\n",
    "\n",
    "Now, let's provide an example scenario for each type of test using Python code.\n",
    "\n",
    "Example Scenario 1: Using a t-test\n",
    "Suppose you are testing the effectiveness of a new drug on blood pressure reduction. You have a sample of 25 patients, and you want to determine if the mean reduction in blood pressure is statistically significant.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a8bf76-6660-4f75-94e7-2356b183833f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject the null hypothesis: The new drug has a significant effect on blood pressure reduction.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Sample data (reduction in blood pressure for 25 patients)\n",
    "sample_data = np.array([8, 10, 5, 12, 6, 9, 11, 7, 4, 9, 8, 7, 10, 6, 12, 9, 11, 5, 8, 10, 6, 7, 9, 8, 11])\n",
    "\n",
    "# Null hypothesis: Mean reduction = 0\n",
    "# Alternative hypothesis: Mean reduction > 0\n",
    "null_mean = 0\n",
    "\n",
    "# Perform one-sample t-test\n",
    "t_statistic, p_value = stats.ttest_1samp(sample_data, null_mean, alternative='greater')\n",
    "\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis: The new drug has a significant effect on blood pressure reduction.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: The new drug does not have a significant effect on blood pressure reduction.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba3ebab-24b5-4be8-bff4-d752b4dc1594",
   "metadata": {},
   "source": [
    "Example Scenario 2: Using a z-test\n",
    "Suppose you are comparing the average sales of two different stores to determine if there is a significant difference in their performances. You have large samples from both stores (more than 30 samples each)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "700cd225-20cc-48c0-ba57-ef56c960447e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject the null hypothesis: There is a significant difference in the average sales of the two stores.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Sample data for Store A and Store B\n",
    "store_a_sales = np.array([500, 520, 480, 510, 490, 525, 515, 530, 510, 505, 495, 505, 515, 520, 500, 495, 510, 530, 515, 525, 505, 520, 530, 495, 490, 515, 525, 535, 505, 510, 495])\n",
    "store_b_sales = np.array([550, 580, 520, 560, 540, 575, 560, 590, 570, 555, 565, 580, 570, 565, 550, 545, 560, 580, 570, 580, 560, 575, 590, 555, 540, 570, 590, 600, 565, 570, 555])\n",
    "\n",
    "# Null hypothesis: Mean sales of Store A = Mean sales of Store B\n",
    "\n",
    "# Calculate sample means and standard deviations\n",
    "mean_a = np.mean(store_a_sales)\n",
    "mean_b = np.mean(store_b_sales)\n",
    "std_dev_a = np.std(store_a_sales, ddof=1)  # ddof=1 for unbiased estimate of sample standard deviation\n",
    "std_dev_b = np.std(store_b_sales, ddof=1)\n",
    "\n",
    "# Calculate the standard error of the difference between means\n",
    "se_diff = np.sqrt((std_dev_a**2 / len(store_a_sales)) + (std_dev_b**2 / len(store_b_sales)))\n",
    "\n",
    "# Calculate the z-score\n",
    "z_score = (mean_a - mean_b) / se_diff\n",
    "\n",
    "# Compare the z-score to a critical value\n",
    "alpha = 0.05\n",
    "critical_value = norm.ppf(1 - alpha / 2)\n",
    "\n",
    "# Compare the z-score to the critical value\n",
    "if abs(z_score) > critical_value:\n",
    "    print(\"Reject the null hypothesis: There is a significant difference in the average sales of the two stores.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference in the average sales of the two stores.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f88bbb93-90a5-422e-9e51-0f554a5be267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31a1031-46c2-4257-a7a0-8ab61ab91f57",
   "metadata": {},
   "source": [
    "One-tailed and two-tailed tests are concepts used in hypothesis testing to determine the critical region for making a statistical decision based on sample data. They differ in terms of the directionality of the alternative hypothesis and the way they assess the significance of the results.\n",
    "\n",
    "One-Tailed Test:\n",
    "In a one-tailed test (also known as a one-sided test), the alternative hypothesis specifies a specific direction of effect or difference. This means that you are only interested in deviations from the null hypothesis in one direction (either greater than or less than), and you're not concerned about deviations in the opposite direction.\n",
    "\n",
    "For example, if you are testing whether a new treatment increases the mean score of a test, your one-tailed hypotheses would be:\n",
    "\n",
    "Null hypothesis (H0): The treatment has no effect (mean difference = 0).\n",
    "Alternative hypothesis (Ha): The treatment increases the mean score (mean difference > 0).\n",
    "The critical region for a one-tailed test is located entirely in one tail of the probability distribution (either the upper or lower tail), depending on the direction specified by the alternative hypothesis.\n",
    "\n",
    "Two-Tailed Test:\n",
    "In a two-tailed test (also known as a two-sided test), the alternative hypothesis does not specify a particular direction of effect or difference. This means that you are interested in deviations from the null hypothesis in both directions (either greater than or less than), and you want to assess whether the observed effect is significantly different from what would be expected by chance alone.\n",
    "\n",
    "For example, if you are testing whether a new drug affects the mean weight of a group of patients, your two-tailed hypotheses would be:\n",
    "\n",
    "Null hypothesis (H0): The drug has no effect (mean difference = 0).\n",
    "Alternative hypothesis (Ha): The drug has an effect (mean difference ≠ 0).\n",
    "The critical region for a two-tailed test is divided between both tails of the probability distribution, with equal probability allocated to each tail.\n",
    "\n",
    "Choosing Between One-Tailed and Two-Tailed Tests:\n",
    "The choice between a one-tailed and two-tailed test depends on the specific research question and the hypothesis you want to test. If you have a specific directional hypothesis (e.g., you expect an increase or decrease), a one-tailed test may be appropriate. On the other hand, if you are open to detecting any significant difference, regardless of direction, a two-tailed test is more suitable.\n",
    "\n",
    "When selecting the type of test, it's important to define your hypotheses clearly and consider the context of the problem to make an informed decision.\n",
    "\n",
    "In summary, the key difference between one-tailed and two-tailed tests lies in the directionality of the alternative hypothesis and the way they allocate the critical region for making statistical decisions based on sample data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b4dc0d8-c548-4031-a049-a8608936607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb9f449-2942-49c0-81e6-31cca72df7f3",
   "metadata": {},
   "source": [
    "In hypothesis testing, Type I and Type II errors are two types of mistakes that can occur when making decisions about a null hypothesis. These errors are related to the incorrect rejection or non-rejection of the null hypothesis based on sample data.\n",
    "\n",
    "Type I Error (False Positive):\n",
    "A Type I error occurs when we reject a null hypothesis that is actually true. In other words, we conclude that there is a significant effect or difference when, in reality, there is no effect or difference. The probability of making a Type I error is denoted by the symbol α (alpha) and is often set as the significance level of the test.\n",
    "\n",
    "Type II Error (False Negative):\n",
    "A Type II error occurs when we fail to reject a null hypothesis that is actually false. This means that we miss detecting a significant effect or difference when it does exist. The probability of making a Type II error is denoted by the symbol β (beta).\n",
    "\n",
    "Here are example scenarios for each type of error:\n",
    "\n",
    "Example Scenario for Type I Error:\n",
    "Suppose a pharmaceutical company is testing a new drug to reduce cholesterol levels. The null hypothesis (H0) is that the drug has no effect on cholesterol levels. The alternative hypothesis (Ha) is that the drug reduces cholesterol levels.\n",
    "\n",
    "Type I Error: Rejecting the null hypothesis (H0) when it is actually true (the drug has no effect).\n",
    "\n",
    "Example Scenario for Type II Error:\n",
    "Continuing with the same pharmaceutical company, let's say the drug actually does reduce cholesterol levels by a clinically significant amount, but the sample size used in the study is too small or the drug's effect is subtle.\n",
    "\n",
    "Type II Error: Failing to reject the null hypothesis (H0) when it is actually false (the drug does have a significant effect).\n",
    "\n",
    "In both scenarios, there is a possibility of making an incorrect decision. The balance between Type I and Type II errors is controlled by the choice of significance level (α) and the power of the test (1 - β). Increasing the significance level (e.g., from 0.05 to 0.10) will decrease the chance of Type II errors but increase the chance of Type I errors. Conversely, increasing the power of the test will decrease the chance of Type II errors but may increase the chance of Type I errors.\n",
    "\n",
    "Hypothesis testing aims to strike a balance between these two types of errors based on the specific context of the study and its associated risks.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f54d319-59e2-427b-a4fe-01e948fe3421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736e1085-cfef-4a83-9f45-452a26cb4620",
   "metadata": {},
   "source": [
    "ayes's Theorem is a fundamental concept in probability theory and statistics that describes how to update our beliefs or probabilities about an event based on new evidence or information. It is particularly useful in situations where we have prior knowledge and want to update that knowledge with new data.\n",
    "\n",
    "The formula for Bayes's Theorem is:\n",
    "\n",
    "P(A∣B)= \n",
    "P(B)\n",
    "P(B∣A)⋅P(A)\n",
    "​\n",
    " \n",
    "\n",
    "\n",
    " \n",
    "\n",
    "Where:\n",
    "\n",
    "�\n",
    "(\n",
    "�\n",
    "∣\n",
    "�\n",
    ")\n",
    "P(A∣B) is the posterior probability of event A given evidence B.\n",
    "�\n",
    "(\n",
    "�\n",
    "∣\n",
    "�\n",
    ")\n",
    "P(B∣A) is the likelihood of evidence B given that event A has occurred.\n",
    "�\n",
    "(\n",
    "�\n",
    ")\n",
    "P(A) is the prior probability of event A.\n",
    "�\n",
    "(\n",
    "�\n",
    ")\n",
    "P(B) is the probability of evidence B.\n",
    "Now, let's illustrate Bayes's Theorem with a simple example in Python code:\n",
    "\n",
    "Suppose we have a diagnostic test for a rare disease. The test is not perfect and can produce false positives and false negatives. We want to calculate the probability that a person actually has the disease given that they tested positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72ac79e7-f6ad-408d-8bbe-dba3e32e5684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of having the disease given testing positive: 0.08755760368663597\n"
     ]
    }
   ],
   "source": [
    "# Prior probabilities\n",
    "p_disease = 0.01  # Probability of having the disease\n",
    "p_no_disease = 1 - p_disease  # Probability of not having the disease\n",
    "\n",
    "# Sensitivity and specificity of the test\n",
    "p_pos_given_disease = 0.95  # Probability of testing positive given having the disease\n",
    "p_neg_given_no_disease = 0.90  # Probability of testing negative given not having the disease\n",
    "\n",
    "# Calculate the probability of testing positive (P(B))\n",
    "p_positive = (p_disease * p_pos_given_disease) + (p_no_disease * (1 - p_neg_given_no_disease))\n",
    "\n",
    "# Calculate the posterior probability of having the disease given testing positive (P(A|B))\n",
    "p_disease_given_positive = (p_pos_given_disease * p_disease) / p_positive\n",
    "\n",
    "print(\"Probability of having the disease given testing positive:\", p_disease_given_positive)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918b3dd1-9396-4d85-bbc4-5873b703a4ba",
   "metadata": {},
   "source": [
    "In this example, we calculate the probability of having the disease given testing positive using Bayes's Theorem. We use the prior probability of having the disease, the sensitivity and specificity of the test, and the probability of testing positive or negative to update our belief about whether a person actually has the disease given a positive test result. The result will provide the updated probability of having the disease after considering the test result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da75e59a-c31e-4d3c-b06c-2589c965d76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c925580-add4-4752-bf0b-8a563179254b",
   "metadata": {},
   "source": [
    "A confidence interval is a range of values around a sample statistic (such as the mean or proportion) that is constructed in such a way that it is likely to contain the true population parameter with a specified level of confidence. It provides a measure of the uncertainty associated with estimating a population parameter based on a sample.\n",
    "\n",
    "In other words, a confidence interval gives us a range of values within which we believe the true population parameter is likely to fall. The specified level of confidence, often denoted as \n",
    "1\n",
    "−\n",
    "�\n",
    "1−α, indicates the probability that the interval contains the true parameter.\n",
    "\n",
    "Here's how to calculate a confidence interval using an example in Python:\n",
    "\n",
    "Suppose we have a dataset representing the ages of a sample of individuals, and we want to calculate a 95% confidence interval for the population mean age."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43988769-7511-46e9-8c7c-49f9d0375c7a",
   "metadata": {},
   "source": [
    "In this example, we calculate a 95% confidence interval for the population mean age using the t-distribution. We calculate the sample mean, sample standard deviation, and the critical value from the t-distribution based on the specified confidence level and degrees of freedom. Then, we calculate the margin of error and construct the confidence interval around the sample mean. The result is a range of values within which we can be 95% confident that the true population mean age falls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fc44220-2105-4029-a3c6-75aa537c4c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Mean: 30.7\n",
      "Confidence Interval: (28.732226646206882, 32.667773353793116)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "\n",
    "# Sample data (ages of individuals)\n",
    "ages = np.array([28, 32, 35, 29, 30, 31, 34, 27, 33, 28])\n",
    "\n",
    "# Calculate sample mean and standard deviation\n",
    "sample_mean = np.mean(ages)\n",
    "sample_std = np.std(ages, ddof=1)  # ddof=1 for unbiased estimate of sample standard deviation\n",
    "\n",
    "# Set the confidence level and degrees of freedom\n",
    "confidence_level = 0.95\n",
    "df = len(ages) - 1  # degrees of freedom\n",
    "\n",
    "# Calculate the critical value from the t-distribution\n",
    "alpha = 1 - confidence_level\n",
    "t_critical = t.ppf(1 - alpha / 2, df)\n",
    "\n",
    "# Calculate the margin of error\n",
    "margin_of_error = t_critical * (sample_std / np.sqrt(len(ages)))\n",
    "\n",
    "# Calculate the confidence interval\n",
    "confidence_interval = (sample_mean - margin_of_error, sample_mean + margin_of_error)\n",
    "\n",
    "print(\"Sample Mean:\", sample_mean)\n",
    "print(\"Confidence Interval:\", confidence_interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f73e85e5-65d1-4344-b5e5-dba2d64cb338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4040b70b-e97b-422d-9cbc-4e847dce3456",
   "metadata": {},
   "source": [
    " Let's consider a classic example involving a diagnostic test for a medical condition. Suppose there's a rare disease, and you want to calculate the probability that a person has the disease given that they tested positive for it.\n",
    "\n",
    "Problem:\n",
    "You know that the prevalence of the disease in the population is 0.2% (0.002), and the diagnostic test has the following characteristics:\n",
    "\n",
    "Sensitivity: The probability of a positive test result given that the person has the disease is 95% (0.95).\n",
    "Specificity: The probability of a negative test result given that the person does not have the disease is 90% (0.90).\n",
    "You need to calculate the probability that a person has the disease given that they tested positive (i.e., the posterior probability).\n",
    "\n",
    "Solution using Bayes' Theorem:\n",
    "Bayes' Theorem allows us to update our belief about the probability of an event occurring based on new evidence. In this case, we want to calculate the probability of having the disease (event A) given a positive test result (event B):\n",
    "P(A∣B)= \n",
    "P(B)\n",
    "P(B∣A)⋅P(A)\n",
    "​\n",
    "Where:\n",
    "\n",
    "�\n",
    "(\n",
    "�\n",
    "∣\n",
    "�\n",
    ")\n",
    "P(A∣B) is the posterior probability of having the disease given a positive test result.\n",
    "�\n",
    "(\n",
    "�\n",
    "∣\n",
    "�\n",
    ")\n",
    "P(B∣A) is the probability of a positive test result given that the person has the disease (sensitivity).\n",
    "�\n",
    "(\n",
    "�\n",
    ")\n",
    "P(A) is the prior probability of having the disease.\n",
    "�\n",
    "(\n",
    "�\n",
    ")\n",
    "P(B) is the probability of a positive test result, calculated as the sum of the probabilities of a positive result given having the disease and a positive result given not having the disease.\n",
    "Now let's calculate the posterior probability using the given values:\n",
    "\n",
    "The calculated posterior probability indicates that there's approximately a 2.14% chance that a person actually has the disease given a positive test result. This illustrates how Bayes' Theorem allows us to update our initial belief (prior probability) based on new evidence (test results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a158835e-c55e-4c86-a404-bdaae80028d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior Probability of Having the Disease Given a Positive Test Result: 0.01868239921337267\n"
     ]
    }
   ],
   "source": [
    "# Given values\n",
    "p_disease = 0.002    # Prior probability of having the disease\n",
    "p_no_disease = 1 - p_disease  # Prior probability of not having the disease\n",
    "p_pos_given_disease = 0.95     # Sensitivity of the test (P(B|A))\n",
    "p_pos_given_no_disease = 1 - 0.90  # False positive rate of the test (1 - specificity)\n",
    "\n",
    "# Calculate the probability of a positive test result (P(B))\n",
    "p_positive = (p_disease * p_pos_given_disease) + (p_no_disease * p_pos_given_no_disease)\n",
    "\n",
    "# Calculate the posterior probability of having the disease given a positive test result (P(A|B))\n",
    "p_disease_given_positive = (p_pos_given_disease * p_disease) / p_positive\n",
    "\n",
    "print(\"Posterior Probability of Having the Disease Given a Positive Test Result:\", p_disease_given_positive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69e5e987-9356-4cd1-8b99-4be013dfbc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91dc21f8-2dd2-4d99-8ec8-935612f4aa28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical Value: 1.959963984540054\n",
      "95% Confidence Interval: (49.02001800772997, 50.97998199227003)\n"
     ]
    }
   ],
   "source": [
    "mean_sp=50\n",
    "std_sp=5\n",
    "confidence_level=0.95\n",
    "alpha=1-confidence_level\n",
    "sample_size=100\n",
    "critical_value=norm.ppf(1-alpha/2)\n",
    "margin_of_error=critical_value*(std_sp / np.sqrt(sample_size))\n",
    "confidence_interval_lower = mean_sp - margin_of_error\n",
    "confidence_interval_upper = mean_sp + margin_of_error\n",
    "print(\"Critical Value:\", critical_value)\n",
    "print(\"95% Confidence Interval:\", (confidence_interval_lower, confidence_interval_upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "879cc8cd-cc0e-43d0-93a1-b53b4619963a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f23e0f8-e797-4df7-92ba-dffa64b72a59",
   "metadata": {},
   "source": [
    "The margin of error in a confidence interval is the range around a sample statistic (such as the mean or proportion) that provides an estimate of the uncertainty associated with our estimate of the true population parameter. It quantifies the precision of our estimate. A larger margin of error indicates greater uncertainty, while a smaller margin of error indicates higher precision.\n",
    "\n",
    "The formula for calculating the margin of error in a confidence interval is generally:\n",
    "\n",
    "Margin of Error = Critical Value * (Standard Deviation / √Sample Size)\n",
    "\n",
    "Here's how sample size affects the margin of error:\n",
    "\n",
    "Inverse Relationship: As the sample size increases, the margin of error decreases. This means that with a larger sample size, our estimate becomes more precise, and the range around the estimate becomes narrower.\n",
    "\n",
    "More Data Points: A larger sample size provides more data points and better represents the population, reducing the variability of the estimate. This reduced variability results in a smaller standard deviation in the formula, which in turn leads to a smaller margin of error.\n",
    "\n",
    "Better Confidence: With a larger sample, the confidence interval captures the true population parameter more accurately, making it more likely that the true parameter falls within the interval.\n",
    "\n",
    "Example Scenario:\n",
    "Suppose you are conducting a political survey to estimate the proportion of voters in a city who support a particular candidate. You want to calculate a 95% confidence interval for the proportion based on two different sample sizes: 500 and 1000.\n",
    "\n",
    "For both cases, let's assume you find a sample proportion of 0.60 (60%) who support the candidate and a standard deviation of 0.04\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cde31c4-75c7-4bae-9a6f-cdb8f7e7cbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Margin of Error for Sample Size 500: 0.003506090162306326\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "sample_size_500 = 500\n",
    "sample_proportion = 0.60\n",
    "standard_deviation = 0.04\n",
    "confidence_level = 0.95\n",
    "\n",
    "critical_value = norm.ppf(1 - (1 - confidence_level) / 2)\n",
    "margin_of_error_500 = critical_value * (standard_deviation / np.sqrt(sample_size_500))\n",
    "\n",
    "print(\"Margin of Error for Sample Size 500:\", margin_of_error_500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84e5f035-3d83-476b-a858-5e4de0a90e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Margin of Error for Sample Size 1000: 0.0024791801292182464\n"
     ]
    }
   ],
   "source": [
    "sample_size_1000 = 1000\n",
    "\n",
    "critical_value = norm.ppf(1 - (1 - confidence_level) / 2)\n",
    "margin_of_error_1000 = critical_value * (standard_deviation / np.sqrt(sample_size_1000))\n",
    "\n",
    "print(\"Margin of Error for Sample Size 1000:\", margin_of_error_1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a73148a-393d-4754-8347-0b528f4cb34c",
   "metadata": {},
   "source": [
    "Margin of Error for Sample Size 500: 0.025312214820751107\n",
    "Margin of Error for Sample Size 1000: 0.017889881753416056\n",
    "In this example, you can see that the margin of error is smaller for the larger sample size (1000) compared to the smaller sample size (500). This aligns with the principle that larger sample sizes lead to more precise estimates and narrower confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5c895c4-f60c-470b-9357-9d294fb361c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eda2a6ae-afa8-47de-ab31-c1237ade5da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "mean=70\n",
    "std=5\n",
    "data_point=75\n",
    "z_score = (((data_point)-mean)/std)\n",
    "\n",
    "print(\"Z-Score:\", z_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd0ddb03-fc2b-494b-9507-3ca13883f206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 10"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6763680d-6366-444a-b585-c44fc4af5e1b",
   "metadata": {},
   "source": [
    "To conduct a hypothesis test to determine if the drug is significantly effective, we need to set up the null and alternative hypotheses, choose a significance level (alpha), calculate the test statistic (t-score), and compare it to the critical value from the t-distribution.\n",
    "\n",
    "Given:\n",
    "\n",
    "Sample size (\n",
    "�\n",
    "n or sample count) = 50\n",
    "Sample mean (\n",
    "�\n",
    "ˉ\n",
    "x\n",
    "ˉ\n",
    " ) = 6 pounds\n",
    "Sample standard deviation (\n",
    "�\n",
    "s) = 2.5 pounds\n",
    "Confidence level = 95%\n",
    "Degrees of freedom (\n",
    "�\n",
    "�\n",
    "df) = \n",
    "�\n",
    "−\n",
    "1\n",
    "n−1\n",
    "Let's perform the hypothesis test using a t-test:\n",
    "Hypotheses:\n",
    "\n",
    "Null Hypothesis (\n",
    "�\n",
    "0\n",
    "H \n",
    "0\n",
    "​\n",
    " ): The drug is not significantly effective (\n",
    "�\n",
    "=\n",
    "0\n",
    "μ=0).\n",
    "Alternative Hypothesis (\n",
    "�\n",
    "�\n",
    "H \n",
    "a\n",
    "​\n",
    " ): The drug is significantly effective (\n",
    "�\n",
    "≠\n",
    "0\n",
    "μ\n",
    "\n",
    "=0).\n",
    "Significance Level:\n",
    "Let's use a significance level of 0.05 (95% confidence level), which means we'll reject the null hypothesis if the p-value is less than 0.05.\n",
    "\n",
    "Calculation of the Test Statistic (t-score):\n",
    "The formula for the t-score is:\n",
    "�\n",
    "=\n",
    "�\n",
    "ˉ\n",
    "−\n",
    "�\n",
    "�\n",
    "/\n",
    "�\n",
    "t= \n",
    "s/ \n",
    "n\n",
    "​\n",
    " \n",
    "x\n",
    "ˉ\n",
    " −μ\n",
    "​\n",
    " \n",
    "\n",
    "Calculate the t-score\n",
    "Calculation of p-value:\n",
    "To calculate the p-value associated with the t-score, we can use the cumulative distribution function (CDF) of the t-distribution. Since this is a two-tailed test, we'll calculate the probability of obtaining a t-score more extreme than the calculated t-score in both tails.\n",
    "Compare p-value to Significance Level:\n",
    "Compare the calculated p-value to the significance level (0.05) to determine whether to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abd1127c-8a02-4f9b-8f08-a2ea36998e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fail to reject the null hypothesis. The drug is not significantly effective.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import t\n",
    "import numpy as np\n",
    "sample_size=50\n",
    "population_mean=0\n",
    "sp_mean=6\n",
    "std=2.5\n",
    "confidence_level=0.95\n",
    "df=sample_size-1\n",
    "alpha=1-confidence_level\n",
    "t_score=((sp_mean-population_mean)/(std)/(np.sqrt(sample_size)))\n",
    "p_value = 2 * (1 - t.cdf(abs(t_score), df))\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"Reject the null hypothesis. The drug is significantly effective.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. The drug is not significantly effective.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57e718e1-a7c4-4fdf-8c59-23f801ca6d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5649d8ad-e96e-47c6-a5b4-6b2a3909bb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval: (0.6081925393809212, 0.6918074606190788)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Given values\n",
    "sample_proportion = 0.65  # 65%\n",
    "sample_size = 500\n",
    "confidence_level = 0.95\n",
    "\n",
    "# Calculate the standard error\n",
    "standard_error = np.sqrt((sample_proportion * (1 - sample_proportion)) / sample_size)\n",
    "\n",
    "# Calculate the critical value from the standard normal distribution\n",
    "alpha = 1 - confidence_level\n",
    "critical_value = norm.ppf(1 - alpha / 2)\n",
    "\n",
    "# Calculate the margin of error\n",
    "margin_of_error = critical_value * standard_error\n",
    "\n",
    "# Calculate the confidence interval\n",
    "confidence_interval_lower = sample_proportion - margin_of_error\n",
    "confidence_interval_upper = sample_proportion + margin_of_error\n",
    "\n",
    "print(\"95% Confidence Interval:\", (confidence_interval_lower, confidence_interval_upper))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8516dced-d7c5-4abf-9e30-53c29146c3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3de48c4-5348-4c91-bb7e-366a39e0d947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject the null hypothesis. The teaching methods have a significant difference in student performance.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "\n",
    "# Given values\n",
    "sample_mean_A = 85\n",
    "sample_std_dev_A = 6\n",
    "sample_size_A = 100\n",
    "\n",
    "sample_mean_B = 82\n",
    "sample_std_dev_B = 5\n",
    "sample_size_B = 100\n",
    "\n",
    "alpha = 0.01\n",
    "\n",
    "# Calculate the pooled standard deviation\n",
    "pooled_std_dev = np.sqrt(((sample_std_dev_A ** 2) + (sample_std_dev_B ** 2)) / 2)\n",
    "\n",
    "# Calculate the degrees of freedom\n",
    "df = sample_size_A + sample_size_B - 2\n",
    "\n",
    "# Calculate the t-score\n",
    "t_score = (sample_mean_A - sample_mean_B) / (pooled_std_dev * np.sqrt((1 / sample_size_A) + (1 / sample_size_B)))\n",
    "\n",
    "# Calculate the critical value from the t-distribution\n",
    "critical_value = t.ppf(1 - alpha / 2, df)\n",
    "\n",
    "# Compare the calculated t-score with the critical value\n",
    "if abs(t_score) > critical_value:\n",
    "    print(\"Reject the null hypothesis. The teaching methods have a significant difference in student performance.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. There is no significant difference in student performance between the teaching methods.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c7762d6-ca56-4077-98e9-52b24c3638a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ab1aad5-b689-4271-86ee-cc2ca07d2614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90% Confidence Interval: (63.13906055411732, 66.86093944588268)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Given values\n",
    "sample_mean = 65\n",
    "population_mean = 60\n",
    "population_std_dev = 8\n",
    "sample_size = 50\n",
    "confidence_level = 0.90\n",
    "\n",
    "# Calculate the critical value from the standard normal distribution\n",
    "alpha = 1 - confidence_level\n",
    "critical_value = norm.ppf(1 - alpha / 2)\n",
    "\n",
    "# Calculate the margin of error\n",
    "margin_of_error = critical_value * (population_std_dev / np.sqrt(sample_size))\n",
    "\n",
    "# Calculate the confidence interval\n",
    "confidence_interval_lower = sample_mean - margin_of_error\n",
    "confidence_interval_upper = sample_mean + margin_of_error\n",
    "\n",
    "print(\"90% Confidence Interval:\", (confidence_interval_lower, confidence_interval_upper))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6246669-dfa4-4644-8792-b7843480fb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1277404-9ac5-43b6-82fb-1ab58552ca17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject the null hypothesis. Caffeine has a significant effect on reaction time.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "\n",
    "# Given values\n",
    "sample_mean = 0.25\n",
    "sample_std_dev = 0.05\n",
    "sample_size = 30\n",
    "confidence_level = 0.90\n",
    "hypothesized_population_mean = 0.28  # Hypothetical value\n",
    "\n",
    "# Calculate the degrees of freedom\n",
    "df = sample_size - 1\n",
    "\n",
    "# Calculate the standard error\n",
    "standard_error = sample_std_dev / np.sqrt(sample_size)\n",
    "\n",
    "# Calculate the t-score\n",
    "t_score = (sample_mean - hypothesized_population_mean) / standard_error\n",
    "\n",
    "# Calculate the critical value from the t-distribution\n",
    "alpha = 1 - confidence_level\n",
    "critical_value = t.ppf(1 - alpha / 2, df)\n",
    "\n",
    "# Compare the calculated t-score with the critical value\n",
    "if abs(t_score) > critical_value:\n",
    "    print(\"Reject the null hypothesis. Caffeine has a significant effect on reaction time.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis. There is no significant effect of caffeine on reaction time.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0114fc3-35dd-428d-af68-60a0b3cfc363",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
