{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a1c811c-0ee8-47dc-ad32-e505dfab7168",
   "metadata": {},
   "source": [
    "Q1. What is anomaly detection and what is its purpose? \n",
    "\n",
    "Q2. What are the key challenges in anomaly detection?\n",
    "\n",
    "Q3. How does unsupervised anomaly detection differ from supervised anomaly detection? \n",
    "\n",
    "Q4. What are the main categories of anomaly detection algorithms? \n",
    "\n",
    "Q5. What are the main assumptions made by distance-based anomaly detection methods? Q6. How does the LOF algorithm compute anomaly scores? \n",
    "\n",
    "Q7. What are the key parameters of the Isolation Forest algorithm? \n",
    "\n",
    "Q8. If a data point has only 2 neighbours of the same class within a radius of 0.5, what is its anomaly score  using KNN with K=10? \n",
    "\n",
    "Q9. Using the Isolation Forest algorithm with 100 trees and a dataset of 3000 data points, what is the  anomaly score for a data point that has an average path length of 5.0 compared to the average path  length of the trees? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83f7cfc-3a61-4023-bb02-c715a4d364b9",
   "metadata": {},
   "source": [
    "Q1. Anomaly detection, also known as outlier detection, is a data mining and machine learning technique that focuses on identifying rare and unusual data points, called anomalies or outliers, within a dataset. Its purpose is to distinguish atypical observations from the majority of normal, expected observations. Anomalies can represent events, patterns, or data points that deviate significantly from the norm and may indicate errors, fraud, or interesting but rare phenomena.\n",
    "\n",
    "Q2. Key challenges in anomaly detection include:\n",
    "\n",
    "Lack of labeled data: Anomaly detection often works in an unsupervised or semi-supervised setting, where anomalies are not explicitly labeled, making it difficult to train and evaluate models.\n",
    "Data imbalance: Anomalies are typically rare, leading to imbalanced datasets, which can affect the performance of traditional machine learning algorithms.\n",
    "Varying definitions of anomalies: Anomalies may vary in nature and importance, making it challenging to define a one-size-fits-all approach.\n",
    "Data dimensionality: High-dimensional data can pose difficulties in defining and identifying anomalies, as the \"curse of dimensionality\" affects the density estimation.\n",
    "\n",
    "Q3. Unsupervised anomaly detection and supervised anomaly detection differ in the following ways:\n",
    "\n",
    "Unsupervised: In unsupervised anomaly detection, the algorithm identifies anomalies without using labeled data. It relies solely on the characteristics of the data itself, such as deviations from data distributions or distance-based methods.\n",
    "Supervised: In supervised anomaly detection, the algorithm requires labeled data where anomalies are explicitly marked. It learns to distinguish between normal and anomalous instances using a labeled training set.\n",
    "\n",
    "Q4. The main categories of anomaly detection algorithms are:\n",
    "\n",
    "Statistical methods: These methods model the statistical properties of the data, such as mean, variance, and distribution, and identify anomalies as data points that deviate significantly from these properties.\n",
    "Distance-based methods: These algorithms compute distances or similarities between data points and identify anomalies as those that are distant from the majority of data.\n",
    "Density-based methods: These methods analyze the density of data points and consider areas with low density as potential anomaly regions.\n",
    "Machine learning methods: Supervised and unsupervised machine learning algorithms, like isolation forests and one-class SVMs, are used for anomaly detection.\n",
    "\n",
    "Q5. Distance-based anomaly detection methods make assumptions that anomalies are far from the majority of data points. These assumptions include:\n",
    "\n",
    "Anomalies are isolated: They are expected to have greater distances or dissimilarity from their nearest neighbors, indicating their isolation from the rest of the data.\n",
    "Normal data forms clusters: The majority of data points are assumed to cluster together, making anomalies stand out due to their distance from these clusters.\n",
    "\n",
    "Q6. The LOF (Local Outlier Factor) algorithm computes anomaly scores by comparing the density of data points in the neighborhood of each point with the density of their neighbors. A lower LOF score indicates a data point that is denser or more similar to its neighbors, while a higher LOF score suggests that the point is less dense and potentially an anomaly.\n",
    "\n",
    "Q7. The key parameters of the Isolation Forest algorithm include:\n",
    "\n",
    "Number of trees (n_estimators): The total number of trees to create in the forest. A higher number of trees can improve accuracy but may increase computation time.\n",
    "Maximum tree depth (max_depth): The maximum depth of each individual tree in the forest. A shallow tree may not model the data well, while a deep tree may lead to overfitting.\n",
    "Subsampling size (max_samples): The number of data points to sample when building each tree. Smaller values can lead to faster training and reduced overfitting.\n",
    "Q8. In KNN (k-nearest neighbors) with K=10, if a data point has only 2 neighbors of the same class within a radius of 0.5, it means that it is relatively isolated within its local neighborhood. In this case, its anomaly score using the KNN algorithm is likely to be higher because it has fewer neighbors of the same class within its defined radius.\n",
    "\n",
    "Q9. In the Isolation Forest algorithm with 100 trees and a dataset of 3000 data points, the anomaly score for a data point with an average path length of 5.0 compared to the average path length of the trees depends on the specifics of the dataset. Generally, a shorter average path length indicates that the data point is easier to isolate, suggesting that it may be more anomalous. However, the exact interpretation of the score depends on the distribution of path lengths in the forest, and there is no universally standardized scale for anomaly scores.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556783ff-6d82-475c-96a1-cc4683d36e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
